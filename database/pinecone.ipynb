{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0156064f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HelloWorld\n"
     ]
    }
   ],
   "source": [
    "print(\"HelloWorld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "423ce2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "path = \"./PDF.pdf\"\n",
    "loader = UnstructuredPDFLoader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438dfa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khatt\\Documents\\Model-Context-Protocol\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    }
   ],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56358109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data[0].page_content)\n",
    "\n",
    "MARKDOWN_SEPARATORS = [\n",
    "    \"\\n#{1,6} \",\n",
    "    \"```\\n\",\n",
    "    \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
    "    \"\\n---+\\n\",\n",
    "    \"\\n___+\\n\",\n",
    "    \"\\n\\n\",\n",
    "    \"\\n\",\n",
    "    \" \",\n",
    "    \"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7072f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=MARKDOWN_SEPARATORS,\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7773cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "processdata =splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "080ab602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './PDF.pdf'}, page_content='Google Cloud’s AI Adoption Framework\\n\\nContents\\n\\nCreating value through AI, every step of the way\\n\\nPart 1: Executive summary\\n\\nThe power of AI ................................................................................................................... 4\\n\\nLeveraging the power of AI ............................................................................................. 5\\n\\nThe AI maturity themes\\n\\nThe AI maturity phases\\n\\nThe AI Maturity Scale\\n\\nPutting it all together\\n\\nNext steps ........................................................................................................................... 12\\n\\nFind out more\\n\\nWork with Google experts\\n\\nPart 2: Technical deep-dive\\n\\nThe AI maturity phases ................................................................................................... 14\\n\\nTactical\\n\\nStrategic\\n\\nTransformational\\n\\nThe AI Maturity Scale ...................................................................................................... 20\\n\\nLearn\\n\\nLead'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='Tactical\\n\\nStrategic\\n\\nTransformational\\n\\nThe AI Maturity Scale ...................................................................................................... 20\\n\\nLearn\\n\\nLead\\n\\nAccess\\n\\nScale\\n\\nSecure\\n\\nAutomate\\n\\nAdditional technical resources .................................................................................... 35\\n\\nCreating value through AI, every step of the way\\n\\nCompanies everywhere are seeking to leverage the power of AI. And\\n\\nrightly so. The smart applications of AI enable organizations to\\n\\nimprove, to scale, and to accelerate the decision-making process\\n\\nacross most business functions, so as to work both more efficiently\\n\\nand more effectively. It can also open up new avenues and new\\n\\nrevenue streams, providing the organization with an additional\\n\\ncompetitive edge.\\n\\nIn short, many believe (as we do) that the enterprises that invest in\\n\\nbuilding industry-specific AI solutions today are positioning\\n\\nthemselves to be the global economic leaders of tomorrow.'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='In short, many believe (as we do) that the enterprises that invest in\\n\\nbuilding industry-specific AI solutions today are positioning\\n\\nthemselves to be the global economic leaders of tomorrow.\\n\\nBut the path to building an effective AI capability is not an easy one.\\n\\nThere are many challenges to overcome. Challenges with the\\n\\ntechnology to develop platforms and solutions. With the people who\\n\\nwill implement and manage that technology. With the data that fuels\\n\\nthe technology. And with the processes that govern the whole of it.\\n\\nHow do you harness the power inherent in AI, while avoiding any\\n\\npotential missteps?\\n\\nThat’s where Google Cloud comes in. Our framework for AI adoption\\n\\nprovides a guide to technology leaders who want to build an effective\\n\\nAI capability, one that enables them to leverage the power of AI to enhance and streamline their business, smoothly and smartly. The\\n\\nframework is informed by Google’s own evolution, innovation, and'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='AI capability, one that enables them to leverage the power of AI to enhance and streamline their business, smoothly and smartly. The\\n\\nframework is informed by Google’s own evolution, innovation, and\\n\\nleadership in AI, including experience deploying AI in production\\n\\nthrough products such as Gmail and Google Photos. It is also inspired by many years of experience helping cloud customers1 — from startups to enterprises, in various industries — to solve complex challenges.2\\n\\n1 Google Cloud Customer Voices Digital Book 2019. 2 Google Cloud named a leader in The Forrester New Wave™: Computer Vision Platforms, Q4 2019.\\n\\nRecent advances in technology are making AI more versatile — and all but indispensable\\n\\n1\\n\\nWith Google Cloud’s AI Adoption Framework, you’ll be able to create\\n\\nand evolve your own transformative AI capability. You’ll have a map\\n\\nfor assessing where you are in the journey and where, at the end of it,\\n\\nyou’d like to be. You’ll have a structure for building scalable AI'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='for assessing where you are in the journey and where, at the end of it,\\n\\nyou’d like to be. You’ll have a structure for building scalable AI\\n\\ncapabilities to create better insights from big data with powerful\\n\\nalgorithms across the entire business.\\n\\nWith Google Cloud as your guide, the path to AI is considerably\\n\\nsmoother.\\n\\n2\\n\\nPart 1:\\n\\nExecutive summary\\n\\nThe power of AI\\n\\nNew ideas are brought to market daily — some from established companies equipped with\\n\\nindustry experience and capital, some from new companies armed with new technologies\\n\\nand a desire to disrupt. What often bridges the gap between plans and outcomes is a\\n\\ncompany’s ability to effectively make data-driven decisions and execute at scale.\\n\\nThis is precisely what artificial intelligence with machine learning (ML)3 companies that know how to take that information and use it well. Machine learning is\\n\\n1 can do for the\\n\\nparticularly adept at finding patterns in complex datasets to solve complex problems,'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='1 can do for the\\n\\nparticularly adept at finding patterns in complex datasets to solve complex problems,\\n\\nincluding perceptual tasks, such as visual perception and speech recognition. The use cases\\n\\nare both wide reaching and dynamic. Manufacturers, for example, are streamlining their\\n\\ncapital expenses by implementing predictive maintenance. Financial institutions are\\n\\nenhancing their risk analysis. Retailers and media providers are personalizing their customer\\n\\nexperience. And the travel industry is offering their customers dynamic pricing predictions.\\n\\nAt the same time, academic and industrial advances in AI have resulted in better tooling,\\n\\nsmarter algorithms, and more effective implementation techniques covering a wide range of\\n\\nuse cases and datasets. These advances — combined with exponential gains in the cost of\\n\\ndata storage, compute power, AI-centric hardware, and cloud computing — have\\n\\ndemocratized AI for industry in an unprecedented way.'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='data storage, compute power, AI-centric hardware, and cloud computing — have\\n\\ndemocratized AI for industry in an unprecedented way.\\n\\nAI and ML are increasingly implicated in companies gaining a competitive edge, with direct\\n\\nand attributable business value. In a research study we conducted in partnership with MIT Technology Review,4 decisions, 5x faster decision-making, and 3x faster execution. Enterprises that invest in\\n\\n2 we found that the adoption of ML results in 2x more data-driven\\n\\nbuilding industry-specific AI solutions are proven to be better positioned as future global economic leaders. By 2030, companies that fully absorb AI could double their cash flow.5\\n\\nMachine learning truly is reshaping the marketplace.'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='Machine learning truly is reshaping the marketplace.\\n\\n3 Artificial intelligence is the theory and development of systems able to perform tasks normally requiring human intelligence, such as visual perception, speech recognition, and decision-making. Machine learning is an effective way for building AI systems through automatically discovering useful patterns from data, rather than feeding human-writ- ten rules to the system. 4 Machine Learning: The New Proving Ground for Competitive Advantage. 5 Notes from the AI frontier: Modeling the impact of AI on the world economy, McKinsey & Company, September 2018.\\n\\n4\\n\\nLeveraging the power of AI\\n\\nHow do you structure your teams for success? How can you create, discover, share, and\\n\\nmanage data assets? How can you leverage native cloud technologies to scale AI? How do\\n\\nyou streamline the process of updating and monitoring your ML models in production?\\n\\nWe have a solution for that.\\n\\nThe AI maturity themes'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='you streamline the process of updating and monitoring your ML models in production?\\n\\nWe have a solution for that.\\n\\nThe AI maturity themes\\n\\nGoogle Cloud’s AI Adoption Framework is anchored in the familiar rubric of people, process,\\n\\ntechnology, and data. The interplay between these four key areas gives rise to six themes:\\n\\nLearn, Lead, Access, Scale, Automate, and Secure. These themes are foundational to the AI\\n\\nAdoption Framework.\\n\\nFigure 1: The AI maturity themes\\n\\n5\\n\\nEach of the themes draws its character from the two areas it bridges:\\n\\nLearn concerns the quality and scale of learning\\n\\nprograms to upskill your staff, hire external talent, and\\n\\naugment your data science and ML engineering staff\\n\\nwith experienced partners. What data and ML skill sets\\n\\nare required in the organization? What data science and\\n\\nengineering roles should be hired? To what extent do\\n\\nlearning plans reflect business needs? What is the\\n\\nnature of the partnership with AI third parties?'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='engineering roles should be hired? To what extent do\\n\\nlearning plans reflect business needs? What is the\\n\\nnature of the partnership with AI third parties?\\n\\nLead concerns the extent to which your data scientists\\n\\nare supported by a mandate from leadership to apply\\n\\nML to business use cases, and the degree to which the\\n\\ndata scientists are cross-functional, collaborative, and\\n\\nself-motivated. How are the teams structured? Do they\\n\\nhave executive sponsorship and empowerment? How\\n\\nare AI projects budgeted, governed, assessed?\\n\\nAccess concerns the extent to which your organization\\n\\nrecognizes data management as a key element to\\n\\nenable AI and the degree to which data scientists can\\n\\nshare, discover, and reuse data and other ML artifacts. How is the dataset created, curated, and annotated?\\n\\nWho owns the dataset? Is it discoverable and reusable?\\n\\nCan you share, reuse, and expand trained models,\\n\\nnotebooks, and other ML components and solutions?\\n\\n6'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='Who owns the dataset? Is it discoverable and reusable?\\n\\nCan you share, reuse, and expand trained models,\\n\\nnotebooks, and other ML components and solutions?\\n\\n6\\n\\nScale concerns the extent to which you use cloud-native\\n\\nML services that scale with large amounts of data and\\n\\nlarge numbers of data processing and ML jobs, with\\n\\nreduced operational overhead. How are cloud-based\\n\\nservices provisioned? Are they on demand or long-\\n\\nliving? How is capacity for workloads allocated?\\n\\nSecure concerns the extent to which you understand and protect your data and ML services from\\n\\nunauthorized and inappropriate access, in addition to\\n\\nensuring responsible and explainable AI. What controls\\n\\nare in place? What strategies govern the whole? How\\n\\ndoes an organization establish trust in its AI capabilities\\n\\nso that it is leveraged to drive business value?\\n\\nAutomate concerns the extent to which you are able to\\n\\ndeploy, execute, and operate technology for data'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='so that it is leveraged to drive business value?\\n\\nAutomate concerns the extent to which you are able to\\n\\ndeploy, execute, and operate technology for data\\n\\nprocessing and ML pipelines in production efficiently,\\n\\nfrequently, and reliably. What triggers a process? How\\n\\ndo you track data lineage? Are your pipelines fault\\n\\ntolerant and resumable? How do you manage logging,\\n\\nmonitoring, and notifications?\\n\\n7\\n\\nThe AI maturity phases\\n\\nYour readiness for success in adopting AI in your business is determined by your current\\n\\nbusiness practices in each of these six themes. For each theme, those practices will fall into\\n\\none of the following phases:\\n\\nTactical: Simple use cases for AI are in place, but they are typically\\n\\nshort-term and narrow. There may be no coherent plan with a strategy\\n\\nfor building out to the future.\\n\\nThe focus is on easy adoption, minimal disruption, and quick wins.\\n\\nStrategic: AI is now used to deliver sustainable business value for the'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='for building out to the future.\\n\\nThe focus is on easy adoption, minimal disruption, and quick wins.\\n\\nStrategic: AI is now used to deliver sustainable business value for the\\n\\norganization, with several ML systems deployed and maintained in\\n\\nproduction, leveraging both ready-to-use and custom models.\\n\\nA broader vision governs AI adoption. ML is no longer seen as the\\n\\ndomain of a special few. Perception starts to move beyond the hype,\\n\\nbecoming a pivotal accelerator for the business.\\n\\nTransformational: AI plays a key role in the organization: stimulating\\n\\ninnovation, supporting agility, and helping to cultivate a culture where\\n\\nexperimentation and learning is continuous and encouraged.\\n\\nML expertise has diffused across lines of business. There is a\\n\\nmechanism in place for scaling and promoting ML capabilities across\\n\\nthe organization.\\n\\n8\\n\\nThe AI Maturity Scale\\n\\nWhen you evaluate the AI maturity themes in light of the three phases, the result is the AI\\n\\nMaturity Scale.'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='the organization.\\n\\n8\\n\\nThe AI Maturity Scale\\n\\nWhen you evaluate the AI maturity themes in light of the three phases, the result is the AI\\n\\nMaturity Scale.\\n\\nSelf-motivated, isolated learning using online resources\\n\\nHiring data science and ML skills\\n\\nThird parties cover the skills gap in the organization\\n\\nOrganizing structured and continuous training programs\\n\\nNo hiring for ML skills\\n\\nStrategic partner selected to provide consulting and specialized knowledge\\n\\nAI adoption driven by individual contributors\\n\\n“Heroic” project manager with team budget\\n\\nCreating a centralized cross- functional advanced analytics team to establish common ML patterns and practices\\n\\nAI/ML link to business goals not always clear\\n\\nSenior executive sponsorship and dedicated budget by C-level for innovative projects\\n\\nAligning AI efforts with business objectives and priorities\\n\\nNo asset sharing\\n\\nManaging an enterprise data warehouse\\n\\nIsolated data islands\\n\\nBuilding a data lake'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='Aligning AI efforts with business objectives and priorities\\n\\nNo asset sharing\\n\\nManaging an enterprise data warehouse\\n\\nIsolated data islands\\n\\nBuilding a data lake\\n\\nDefining and sharing a unified data model\\n\\nCentralized data and ML asset management\\n\\nLearning by embedding data scientists to the business function teams\\n\\nHiring data science and ML talent for innovation with industry expertise\\n\\nPartnering to innovate, co-create, and augment technical resources\\n\\nEndorsement and dedicated budget within each line of business\\n\\nFunction-specific data science teams with domain expertise, in addition to the centralized advanced analytics team\\n\\nInnovation and research teams\\n\\nDiscovering, sharing, and reusing datasets and AI assets\\n\\nStandardized ML feature stores and datasets\\n\\nEncouraging contributions from across the organization\\n\\n9\\n\\nDedicated hardware for cost control\\n\\nWorking with a limited number of small datasets'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='Standardized ML feature stores and datasets\\n\\nEncouraging contributions from across the organization\\n\\n9\\n\\nDedicated hardware for cost control\\n\\nWorking with a limited number of small datasets\\n\\nImplementing private networks with primitive IAM accessed and managed by a dedicated team\\n\\nEnsuring privacy through sensitive data classification and obfuscation\\n\\nEnabling data protection through encryption\\n\\nAd hoc, manual data processing and ML model training and serving\\n\\nHigh-risk changes reviewed and deployed infrequently and manually\\n\\nUsing a fully managed serverless data warehouse for ad hoc querying and data exploration\\n\\nUsing fully managed serverless data services for ingestion and processing\\n\\nUsing fully managed serverless ML services for training and prediction serving\\n\\nImplementing principle of least privilege\\n\\nExploring explainable AI techniques\\n\\nInvesting in establishing AI ethics\\n\\nAutomating (scheduled and event-driven) data pipelines'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='Implementing principle of least privilege\\n\\nExploring explainable AI techniques\\n\\nInvesting in establishing AI ethics\\n\\nAutomating (scheduled and event-driven) data pipelines\\n\\nAutomating ML training and batch-prediction pipelines\\n\\nManaging logging, monitoring, and notifications\\n\\nOperating an integrated ML experimentation and production platform\\n\\nUsing specialized ML accelerators (GPUs, TPUs) on demand\\n\\nOrchestrating end-to-end data and ML pipelines\\n\\nIAM continuously monitored and improved\\n\\nConsidering AI safety and robustness\\n\\nDeveloping fair ML systems\\n\\nImplementing ML training pipelines with continuous integration and delivery\\n\\nImplementing ML prediction services with continuous integration and delivery\\n\\nManaging ML model registry, ML metadata, and ML artifacts\\n\\n10\\n\\nIn each of the themes, you can see what happens when you move from adopting AI\\n\\napproaches ad hoc, to working with them more and more comprehensively across the'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='10\\n\\nIn each of the themes, you can see what happens when you move from adopting AI\\n\\napproaches ad hoc, to working with them more and more comprehensively across the\\n\\norganization — which means deeper and more consistent training for your people, which in\\n\\nturn means streamlined and updated processes, which in turn drives collaboration and, in\\n\\ntime, innovation. The organization transforms.\\n\\nWhen AI has been integrated into all parts of your organization, then you are fully harnessing\\n\\nthe power it offers to transform your position in the industry. But at every step along the way,\\n\\nadding in effective AI capabilities brings benefits.\\n\\nPutting it all together\\n\\nAnd that’s the essence of the framework that Google Cloud uses to guide customers\\n\\nsuccessfully through the process of adopting AI in their organization.\\n\\nWith the framework, you can assess your organization’s AI maturity and determine what'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='successfully through the process of adopting AI in their organization.\\n\\nWith the framework, you can assess your organization’s AI maturity and determine what\\n\\nyou’ll need to bridge the gap to where you’d like to be. While we touch on the Google Cloud\\n\\nproducts, you can use this information however you would like: the framework is technology\\n\\nagnostic. We’re here to offer further guidance, if that alignment dovetails with your vision.\\n\\nWe’ve worked hard to make AI accessible to all, not only ML researchers and engineers, but\\n\\nto a vast array of customers across industries as well. And our ongoing work in tooling,\\n\\nframeworks, datasets, and models is well documented in the open source community. AI and\\n\\nML are central to who we are.\\n\\nWhether or not we accompany you on the journey, however, our framework can help you find\\n\\nyour way, from your initial changes all the way to becoming fully AI-powered.\\n\\n11\\n\\nNext steps\\n\\nFind out more'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='Whether or not we accompany you on the journey, however, our framework can help you find\\n\\nyour way, from your initial changes all the way to becoming fully AI-powered.\\n\\n11\\n\\nNext steps\\n\\nFind out more\\n\\nTo dive more deeply into the details of Google Cloud’s AI Adoption Framework, see Part 2 of\\n\\nthis paper.\\n\\nTo learn about transforming your organization with the cloud, see the Google Cloud Adoption\\n\\nFramework whitepaper. Cloud computing enables organizations to build scalable AI capabilities to create better insights from big data with powerful algorithms.\\n\\nTo learn about setting up a Cloud COE to drive and manage change, see Building a Cloud\\n\\nCenter of Excellence.\\n\\nTo expand your ability to formulate ML solutions to solve real-world problems, to discover\\n\\nrelevant ML use cases, and to start an ML project, consider the Machine Learning for\\n\\nBusiness Professionals course.\\n\\nWork with Google experts\\n\\nGoogle Cloud offers a range of professional consulting services and workshops, which'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='Business Professionals course.\\n\\nWork with Google experts\\n\\nGoogle Cloud offers a range of professional consulting services and workshops, which\\n\\nenable you to work directly with Google’s experts to discover, assess, deploy, and upskill in\\n\\nML. If you need help thinking through some of the questions explored in this paper, get in\\n\\ntouch with your Google Cloud representative or contact us.\\n\\n12\\n\\nPart 2:\\n\\nTechnical deep-dive\\n\\nThe AI maturity phases\\n\\nThere are three natural phases to AI maturity: tactical, strategic, and transformational. Each\\n\\norganization’s current approaches to AI will fall within one of these three phases. Each phase\\n\\noffers opportunities for further exploration and development.\\n\\nTactical\\n\\nCharacteristics\\n\\nOrganizations at the tactical phase are exploring the potential of AI to deliver in the short\\n\\nterm. Use cases tend to be narrow, and developers are typically leveraging exploratory data'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='Organizations at the tactical phase are exploring the potential of AI to deliver in the short\\n\\nterm. Use cases tend to be narrow, and developers are typically leveraging exploratory data\\n\\nanalysis (EDA) tools and ready-to-use AI and ML services for proofs of concept and\\n\\nprototyping, for example, using a prebuilt computer vision service to detect printed and\\n\\nhandwritten text, or using descriptive analytics to create a customer segmentation model.\\n\\nAt this phase, organizations are aware of the promise of advanced analytics,6 seen as unattainable, and for this reason, complex problems are outsourced. Since the ML\\n\\n1 but ML can be\\n\\nprojects that exist do so through individual efforts, those projects might not be aligned with\\n\\nthe organization’s business goals, and so even the most successfully deployed ML projects\\n\\nmay have only limited business impact.\\n\\nAt this phase, too, there may be no process to scale solutions consistency, nor the skill set to\\n\\nsolve complex analytics problems.'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='may have only limited business impact.\\n\\nAt this phase, too, there may be no process to scale solutions consistency, nor the skill set to\\n\\nsolve complex analytics problems.\\n\\nOpportunities for growth and advancement\\n\\nAt this phase, organizations can benefit substantially from better access to data. Integrated,\\n\\ncleaner, and fresher data leads, in turn, to actionable insights better tailored to your needs,\\n\\nwhich translates to sharper and more informed decision-making. Such swift improvement is\\n\\nimmediately validating, and can help to paint a picture for stakeholders of the power of ML.\\n\\n6 Broadly, we think of advanced analytics as the ability to use data science and machine learning to create insight for more effective decision-making.\\n\\n14\\n\\nOrganizations at this phase should look to develop the foundational skill set for core data\\n\\nwrangling and descriptive analytics. To drive effective collaboration across an organization'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='14\\n\\nOrganizations at this phase should look to develop the foundational skill set for core data\\n\\nwrangling and descriptive analytics. To drive effective collaboration across an organization\\n\\nand to innovate with data from many sources, a key next move is to start bringing together\\n\\nsiloed data from the many lines of business into a central, unified data lake, but with\\n\\ndecentralized access. With a central data lake, it’s easier to derive insights from unstructured\\n\\ndata and easier also to perform batch integration for reporting. Data is available through\\n\\ncentralized tooling, but teams do not lose autonomy of access management or data\\n\\nownership.\\n\\nOrganizations at this phase can benefit, too, from the move toward use cases that are feasible and designed to deliver business value, but that begin to tackle increasingly complex\\n\\nproblems.\\n\\nAnd the quality of the analytics solutions improves when the organization focuses on\\n\\ndeveloping core standards:'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='problems.\\n\\nAnd the quality of the analytics solutions improves when the organization focuses on\\n\\ndeveloping core standards:\\n\\nA set of unified standards and technical practices that ensures the security of all data\\n\\naccess and protection\\n\\nA set of common principles and procedures that prevents building any ML that may harm\\n\\nyour brand (such as, for example, inadvertently building socially biased models)\\n\\nStrategic\\n\\nCharacteristics\\n\\nOrganizations at the strategic phase are focused on delivering sustainable business value,\\n\\nwith several ML systems deployed and maintained in production that leverage both ready-to- use and custom models. ML is no longer seen as the domain of a select few, but is instead in\\n\\nthe process of becoming a pivotal accelerator for the business.'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='the process of becoming a pivotal accelerator for the business.\\n\\nAt this phase, organizations typically require a degree of centralized coordination and so they will often create an advanced analytics7 various ML use cases across business functions. This team can be part of a broader Cloud\\n\\n1 team with the right skill set to build solutions for\\n\\n7 A centralized team, spun out from the core Cloud COE. This team should have engineering skills in data, analytics, and ML; and they should operate as the hub in a hub-and-spoke pattern, working closely with other ML and data science teams in the various lines of business.\\n\\n15\\n\\nCenter of Excellence (COE),8 side by side, drawing on business subject matter experts, as required by the use case. The\\n\\n1 where engineers and data scientists with domain expertise work\\n\\ncentralized team aims to achieve several strategic goals:\\n\\n\\n\\nTo ensure consistent standards and governance\\n\\n\\n\\nTo assess the feasibility of new use cases'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='centralized team aims to achieve several strategic goals:\\n\\n\\n\\nTo ensure consistent standards and governance\\n\\n\\n\\nTo assess the feasibility of new use cases\\n\\n\\n\\nTo weigh in on new data collection\\n\\n\\n\\nTo remain current on which products can be bought rather than built\\n\\n\\n\\nTo help build ML solutions for different product teams\\n\\n\\n\\nTo prioritize scarce ML resources around key business problems\\n\\nAs the surrounding organizational fabric matures (for example, increased awareness of AI\\n\\ncapabilities, increasing demand for utilizing those capabilities, increased consistency of\\n\\ntooling and approach), it is more feasible for ML to be used independently in different\\n\\nproducts and business areas.\\n\\nAt this phase, teams have skills in data wrangling and descriptive and predictive analytics;\\n\\nthey use existing frameworks, methods, and techniques to solve a variety of use cases; and\\n\\nthey often deploy custom ML models in production. Teams retrieve their information from a'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='they use existing frameworks, methods, and techniques to solve a variety of use cases; and\\n\\nthey often deploy custom ML models in production. Teams retrieve their information from a\\n\\nsingle source: an enterprise data warehouse (EDW), with complete, consistent, correct, and\\n\\nconcurrent data. Extract, transform, load (ETL) and extract, load, transform (ELT) routines are\\n\\nautomated and scalable.\\n\\nOpportunities for growth and advancement\\n\\nAt this phase, organizations can benefit substantially from developing an AI capability that is\\n\\nmore tailored to their business model and their distinct business needs. And from adding automated processes to their customized models.\\n\\nTechnically, the next key moves are about protecting data quality, preventing ML models from\\n\\ngoing stale, and enabling valuable solutions to be production ready. In addition, common\\n\\npractices and guidelines are established for building secure, ethics-complaint AI solutions.'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='going stale, and enabling valuable solutions to be production ready. In addition, common\\n\\npractices and guidelines are established for building secure, ethics-complaint AI solutions.\\n\\n8 No two Cloud COEs are quite the same. Data science skills are an important part of the picture. However, as the level of maturity deepens and the focus of the Cloud COE evolves, it can make increasing sense to establish a distinct advanced analytics capability. You can read more about what makes an effective Cloud COE in this whitepaper.\\n\\n16\\n\\nOrganizationally, the centralized advanced analytics team with technical ML skills starts to\\n\\nwork smoothly in conjunction with various functional teams with specialized domain\\n\\nexpertise.\\n\\nTransformational\\n\\nCharacteristics\\n\\nOrganizations at the transformational phase are actively using AI to stimulate innovation, to\\n\\nsupport agility, and to cultivate a culture where experimentation and learning is ongoing.'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='Organizations at the transformational phase are actively using AI to stimulate innovation, to\\n\\nsupport agility, and to cultivate a culture where experimentation and learning is ongoing.\\n\\nModels are built and deployed from a unified ML platform, making ML accessible to everyone\\n\\nin the organization.\\n\\nAt this phase, organizations typically model a hybrid approach to AI, with functional or\\n\\nproduct-specific AI teams embedded into the broader product teams — supported by the\\n\\nadvanced analytics team, which might become its own hub or center of excellence. The\\n\\ncentral team enables a mechanism for scaling and cultivating these capabilities across the\\n\\norganization: for example, implementing a mechanism for secondment or talent rotation,\\n\\nwhereby business or product experts are immersed in ML techniques to learn hands-on. Over\\n\\ntime, ML expertise diffuses across lines of business. The role of the centralized advanced'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='whereby business or product experts are immersed in ML techniques to learn hands-on. Over\\n\\ntime, ML expertise diffuses across lines of business. The role of the centralized advanced\\n\\nanalytics team becomes more confined to establishing common patterns and best practices\\n\\nand to providing standard tools and libraries for accelerating ML projects. By contrast, the\\n\\ndata science teams embedded in product groups or lines of business are responsible for\\n\\nbuilding their function-specific ML models. This division of responsibility drives consistency\\n\\nin building high-quality, technical solutions with real business impact.\\n\\nAll teams are empowered through a platform that enables access to useful datasets, prepared features, reusable components, and trained models. That platform is supported by\\n\\nscalable and serverless compute for batch and online data ingestion and processing,\\n\\ndistributed ML training and serving, access to databases with specialized storage and'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='scalable and serverless compute for batch and online data ingestion and processing,\\n\\ndistributed ML training and serving, access to databases with specialized storage and\\n\\nquerying capabilities, and hardware accelerators.\\n\\n17\\n\\nOpportunities for growth and advancement\\n\\nAt this phase, organizations can benefit substantially from focusing on best practices,\\n\\nensuring that AI practices are responsible, that they are based on sound principles, and that\\n\\nAI systems are safe and robust.\\n\\nThe ML platform is supported with tools for continuous integration, continuous training, and\\n\\ncontinuous model serving and monitoring. Building and maintaining such a platform is a\\n\\nshared responsibility between ML and software engineers with skills in infrastructure,\\n\\nDevOps, and SRE.\\n\\nOrganizations in this phase often assemble teams to conduct cutting-edge research and\\n\\npresent at academic conferences and AI events. To do this, they focus their research and'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='DevOps, and SRE.\\n\\nOrganizations in this phase often assemble teams to conduct cutting-edge research and\\n\\npresent at academic conferences and AI events. To do this, they focus their research and\\n\\ninnovation in areas where they have unique capabilities, either in terms of domain\\n\\nunderstanding or data availability, so that they can build a sustainable advantage over time.\\n\\nBesides the competitive edge that such a sustainable advantage provides, the in-house\\n\\nresearch capabilities can add to an organization’s employee value proposition, becoming a\\n\\npoint of differentiation to attract the best talent.\\n\\n18\\n\\nGoogle Cloud smart analytics and AI\\n\\nGoogle Cloud offers a wide set of products that enable organizations to accelerate their AI\\n\\njourney, ranging from ready-to-use AI services to an integrated data science development\\n\\nenvironment for building custom solutions.'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='journey, ranging from ready-to-use AI services to an integrated data science development\\n\\nenvironment for building custom solutions.\\n\\nPrebuilt APIs. Prebuilt AI and ML APIs offer ready access to easy-to-use building blocks that require no in-house ML expertise. These APIs address various perceptual tasks: Vision API, Video\\n\\nAPI, Natural Language API, Speech-to-Text API, Text-to-Speech API, and Translation API.\\n\\nCloud AutoML. Cloud AutoML services allow developers, with limited ML expertise, to build high-quality custom models specific to your business needs. For language, you can use AutoML\\n\\nNatural Language and AutoML Translation. For sight, you can use AutoML Vision and AutoML\\n\\nVideo. For structured data, you can automatically build and deploy models using AutoML Tables.\\n\\nAI solutions. These ready-to-use AI solutions enable you to run your business faster and smoother. Contact Center AI positions you to deliver exceptional customer service, while with'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='AI solutions. These ready-to-use AI solutions enable you to run your business faster and smoother. Contact Center AI positions you to deliver exceptional customer service, while with\\n\\nDocument AI you can easily extract insights, information, and knowledge from enterprise-wide\\n\\ntext sources.\\n\\nAI Platform. Through serverless, scalable training and serving capabilities for custom ML models, AI Platform makes it easy for data scientists to take their ML projects from initial\\n\\nconcept to production and deployment, quickly and cost-effectively. With AI Platform, you can\\n\\nuse Tensorflow Enterprise, which offers enterprise-grade support, performance, and managed\\n\\nservices for your AI workloads, and Explainable AI, which lets you interpret models with\\n\\nconfidence.\\n\\nData management. Cloud Storage and BigQuery provide you with a powerful foundation for evolving from siloed data to a centralized data lake, driving enterprise-grade data management.'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='confidence.\\n\\nData management. Cloud Storage and BigQuery provide you with a powerful foundation for evolving from siloed data to a centralized data lake, driving enterprise-grade data management.\\n\\nBigQuery ML also enables you to build powerful ML models without moving any data out of your\\n\\ndata warehouse. In addition, Google Cloud provides a variety of data services for various\\n\\noperational and analytical workloads, including Cloud SQL, Cloud Spanner, Cloud Bigtable,\\n\\nFirestore, and Memorystore. With Cloud Pub/Sub, Dataflow, Cloud Data Fusion, and Dataproc,\\n\\nyou can implement batch and real-time data ingestion and processing at scale.\\n\\nAutomation and instrumentation. Google Cloud provides tools to manage your ML systems in production at scale. With AI Platform Pipelines and Cloud Composer, you can\\n\\norchestrate and automate data and ML pipelines. Cloud Build and Container Registry enable you\\n\\nto build and deploy custom ML systems.\\n\\n19\\n\\nThe AI Maturity Scale'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='orchestrate and automate data and ML pipelines. Cloud Build and Container Registry enable you\\n\\nto build and deploy custom ML systems.\\n\\n19\\n\\nThe AI Maturity Scale\\n\\nWhen you evaluate the six AI maturity themes in terms of the three AI maturity phases —\\n\\nwhere each phase is descriptive of how a given organization is currently functioning in that\\n\\ntheme — you get the AI Maturity Scale.\\n\\nIn each of the themes, you can see what happens when an organization moves from\\n\\nexperimenting with ML tools and technologies, to working with them more strategically, to\\n\\nbuilding a transformational AI capability.\\n\\nLearn\\n\\nBridging People and Technology, “Learn” concerns the quality and scale of\\n\\nlearning programs to upskill your staff, hire outside talent, and augment your\\n\\ndata science and ML engineering staff with experienced partners.\\n\\nAn organization’s maturity in the Learn theme reflects that organization’s ability both to keep'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content=\"data science and ML engineering staff with experienced partners.\\n\\nAn organization’s maturity in the Learn theme reflects that organization’s ability both to keep\\n\\nup with the latest advances in ML and to evolve AI capabilities toward solving ever more\\n\\ncomplex business problems.\\n\\nTactical maturity\\n\\nLearning about data science and ML is self-motivated by a few members of your IT and data\\n\\nteams, using publicy available online resources. While this approach is useful for developing\\n\\ntechnical skills around AI and ML in general, the training courses don’t follow a planned learning path that is aligned with your organization's current and future needs. Meanwhile, a\\n\\nfew members may be working on ML prototypes, but when faced with a compelling use case\\n\\nwhere ML is needed, your organization tends to turn to third-party consultants, rather than\\n\\nhiring to fill the skill set gaps in-house.\\n\\nStrategic maturity\"),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='where ML is needed, your organization tends to turn to third-party consultants, rather than\\n\\nhiring to fill the skill set gaps in-house.\\n\\nStrategic maturity\\n\\nYou’re starting to build greater AI capability in-house by hiring the required data science and ML engineering skills. As there are plenty of job titles and descriptions in the field of ML,9 your focus is on the skills and seniority levels that the organization needs.\\n\\n9 For a breakdown of the top 10 role profiles needed in a data science team, see this article from Google’s Head of Decision Intelligence.\\n\\n1\\n\\n20\\n\\nTo ensure that your team is well qualified to use the necessary tools and technology, you’re\\n\\ndeveloping clear learning paths with certifications and aligning those paths with your\\n\\norganization’s priority use cases. You’ve recognized that the field of AI is constantly changing,\\n\\nand you keep up with those changes by following relevant events, conferences, and experts'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='organization’s priority use cases. You’ve recognized that the field of AI is constantly changing,\\n\\nand you keep up with those changes by following relevant events, conferences, and experts\\n\\nin the field. You strive to do this systematically, providing employees with training\\n\\nopportunities and requirements to fulfill.\\n\\nIn addition, you choose a strategic partner for advisory, consultation, and program\\n\\nmanagement, someone who also provides specialized knowledge in specific AI and ML use\\n\\ncases (for example, chatbots and conversational apps). You use partnerships to help accelerate your AI adoption by taking advantage of best practices and other organizational\\n\\nlessons that experienced AI and ML subject matter experts bring to the table.\\n\\nTransformational maturity\\n\\nYou aim to head-hunt well-known AI and ML talent to lead increasing research and innovation\\n\\nefforts — while also gaining a greater reputation for effective talent development. Both'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='You aim to head-hunt well-known AI and ML talent to lead increasing research and innovation\\n\\nefforts — while also gaining a greater reputation for effective talent development. Both\\n\\nindustry expertise (like finance, healthcare, telco) and domain expertise (churn prediction,\\n\\ncredit risk assessment, medical diagnostics) become increasingly important for hiring great\\n\\ncandidates. This talent and experience is essential for solving groundbreaking domain-\\n\\nspecific problems with AI.\\n\\nFor learning and development, you encourage peer-to-peer and community learning, creating\\n\\nan internal knowledge base, wikis, and tailored courses and learning tracks. You also\\n\\norganize internal conferences to showcase AI applications and promote knowledge sharing.\\n\\nEnabling rotations across business functions ensures not only tighter collaboration between\\n\\nmembers of different teams, but also an exchange of experience and learning on the job. This'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content=\"Enabling rotations across business functions ensures not only tighter collaboration between\\n\\nmembers of different teams, but also an exchange of experience and learning on the job. This\\n\\nmechanism for diffusing and developing talent across your organization can become part of\\n\\nyour employee value proposition, helping to attract the best talent. This can, in turn, help start\\n\\na virtuous talent cycle.\\n\\nAt this maturity phase, a partnership can evolve to become a co-creation relationship, where\\n\\nboth you and your partners' ML researchers and engineers work together to break new\\n\\nground and solve cutting-edge problems in the field. Such research also becomes part of\\n\\nyour value proposition for employees, and a competitive advantage in the market.\\n\\n21\\n\\nLead\\n\\nBridging People and Process, “Lead” concerns the extent to which your data\\n\\nscientists are supported by a mandate from leadership to apply ML to\\n\\nbusiness use cases, and the degree to which the data scientists are cross-\"),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='scientists are supported by a mandate from leadership to apply ML to\\n\\nbusiness use cases, and the degree to which the data scientists are cross-\\n\\nfunctional, collaborative, and self-motivated.\\n\\nAn organization’s maturity in the Lead theme reflects the effectiveness with which that\\n\\norganization will adopt AI in line with business priorities.\\n\\nTactical maturity\\n\\nAI adoption is driven across your organization by individual contributors or a manager within\\n\\none project team, with little or no executive sponsorship. There is typically limited\\n\\ncollaboration between data scientists in different teams, and there is often an unclear line of\\n\\nsight between ML initiatives and the organization’s strategic goals. You’re identifying the right\\n\\nuse cases for applying ML and also pursuing executive sponsorship. The focus is to explore\\n\\nthe power and prove the value of ML to stakeholders, while the funding is part of the project\\n\\nteam’s budget.\\n\\nThe first successful use case'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='the power and prove the value of ML to stakeholders, while the funding is part of the project\\n\\nteam’s budget.\\n\\nThe first successful use case\\n\\nThe first step to realizing value from AI is to identify the right business problem and a sponsor committed to using AI to solve that problem. To ensure alignment, start with your organization’s\\n\\nbusiness strategy and key priorities. Identify the right business priority use cases to address\\n\\nwith AI, and find the senior executive to own it. Work with their team to get their buy-in and\\n\\nsponsorship. AI projects are more likely to be successful when they have a senior executive\\n\\nsponsor who will champion them with other leaders in your organization.\\n\\n22\\n\\nStrategic maturity\\n\\nYour senior executives support AI capabilities and projects to deliver value to several\\n\\nbusiness functions, an approach that amounts to a competitive advantage. You’ve begun to\\n\\nestablish a mechanism for standardizing practices and guidelines and sharing accumulated'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='business functions, an approach that amounts to a competitive advantage. You’ve begun to\\n\\nestablish a mechanism for standardizing practices and guidelines and sharing accumulated\\n\\nknowledge. To accomplish this, you may have put into place a centralized advanced analytics\\n\\nteam, with a dedicated budget established by a set of C-level executives with a technology\\n\\nagenda.\\n\\nThe advanced analytics team works on delivering prioritized projects or short-term consulting to other teams. In addition, they proactively evangelize and advocate their AI\\n\\ncapabilities to other lines of business, clarifying how AI can address the various use cases.\\n\\nWhat members of this team all share is a forward-thinking and self-motivated interest in\\n\\nusing AI to deliver business value. Equally important, they share an understanding of the\\n\\nimportance of scaling this impact by growing and embedding data science capabilities in\\n\\nfunctional teams across the business.\\n\\nTransformational maturity'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='importance of scaling this impact by growing and embedding data science capabilities in\\n\\nfunctional teams across the business.\\n\\nTransformational maturity\\n\\nEach functional team has its own data scientists with the right domain-specific expertise and\\n\\nsupport from a technical project manager with the right organizational influence. This\\n\\nensures that models can be successfully deployed and scaled in a timely manner. This team\\n\\nis supported by a centralized advanced analytics team, which provides standards and best\\n\\npractices, as well as the tooling and platform for implementing ML projects. Having both a\\n\\ncentralized team and embedded data scientists in the business functions ensures technical\\n\\nstandards and business alignment, respectively.\\n\\nWith standards firmly in place, and the structure to support further investigation, research\\n\\nand innovation activities flourish. This work is sponsored by senior executives both to solve'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='With standards firmly in place, and the structure to support further investigation, research\\n\\nand innovation activities flourish. This work is sponsored by senior executives both to solve\\n\\ncutting-edge business problems and to establish the organization’s name as a market leader.\\n\\nIn addition, to stimulate innovation, you facilitate competitions that reward employees for\\n\\nsharing ideas on how ML can solve key problems.\\n\\n23\\n\\nYour C-level executives act passionately, continuously demonstrating active sponsorship for\\n\\nAI projects and encouraging contributions from across the organization. The leadership\\n\\nfunctions effectively for an AI-driven environment, fostering a culture of blamelessness and\\n\\nopen communication channels, where sharing failures openly is encouraged and mistakes\\n\\nare treated as opportunities for improvement. Experimentation drives innovation and market\\n\\nsuccess. Teams are free to try out many different ideas with the goal of failing faster, failing'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='are treated as opportunities for improvement. Experimentation drives innovation and market\\n\\nsuccess. Teams are free to try out many different ideas with the goal of failing faster, failing\\n\\nbetter, and learning from the experience to improve and innovate.\\n\\n24\\n\\nAccess\\n\\nBridging People and Data, “Access” concerns the extent to which your\\n\\norganization recognizes data management as a key element to enable AI and\\n\\nthe degree to which data scientists can share, discover, and reuse data and\\n\\nother ML assets.\\n\\nAn organization’s maturity in the Access theme reflects that organization’s ability both to\\n\\naccelerate an ML project and to improve the adoption of the AI capabilities across different\\n\\nteams and functions.\\n\\nTactical maturity\\n\\nEach team usually manages its own data island and ML assets,10 other teams. Even within the same team, it might not be possible to reuse assets, as the\\n\\n1 with no sharing among\\n\\ntechnology and processes have not been standardized yet.'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='1 with no sharing among\\n\\ntechnology and processes have not been standardized yet.\\n\\nIn a bid to update your data management and access strategy, you are looking into building a\\n\\nunified data lake, containing the raw (structured and unstructured) data feeds, for example,\\n\\nusing Cloud Storage. This data lake can then form the foundation for collecting, curating, and\\n\\nsharing data across the organization, that is, for building managed information stores.\\n\\nStrategic maturity\\n\\nYou recognize data as a vital enterprise asset that fuels AI, and so you’ve improved both the\\n\\nutilization and the management of data, working to keep it safe and useful. You likely have invested in an EDW, which provides a unified data model, with an integrated, consistent\\n\\ninformation store for various business functions. You have also made data quality\\n\\nmanagement a business priority to ensure the right foundation for analytics and AI. The EDW,'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='information store for various business functions. You have also made data quality\\n\\nmanagement a business priority to ensure the right foundation for analytics and AI. The EDW,\\n\\nwhich can be implemented using BigQuery, empowers data analysts in their reporting, data\\n\\nscientists in their exploratory data analysis and ML experimentation tasks, and other\\n\\nbusiness intelligence (BI) activities.\\n\\n10 ML assets refers to notebooks, trained models, reusable components, and code snippets. From the strategic phase onwards, solution templates are another asset used to create consistency.\\n\\n25\\n\\nIn addition, your organization is starting now to put together a centralized repository for ML\\n\\nassets and to develop tools for annotating and categorizing data, for example, using Data\\n\\nCatalog. Such assets are created and curated by a centralized advanced analytics team,\\n\\nwhich creates and provides access to such assets on demand. Although each team'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='Catalog. Such assets are created and curated by a centralized advanced analytics team,\\n\\nwhich creates and provides access to such assets on demand. Although each team\\n\\nmaintains their own assets, there is typically limited discoverability and shareability outside\\n\\nthis team.\\n\\nTo facilitate AI adoption, you’re looking now at ways of better handling sensitive data and of\\n\\nbetter protecting data overall.\\n\\nTransformational maturity\\n\\nYou are actively working to develop the technology and processes to allow data scientists to\\n\\ncreate, share, discover, and reuse data and ML assets across different teams and functions,\\n\\nwhich accelerates the launch of new ML-based services. And your teams are using\\n\\nspecialized data storage tools (such as Cloud SQL, Cloud Spanner, Cloud Bigtable, Firestore,\\n\\nand Memorystore) based on the requirements for data volume, structure, and consistency\\n\\nand on read/write workloads.'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='and Memorystore) based on the requirements for data volume, structure, and consistency\\n\\nand on read/write workloads.\\n\\nTo help standardize the definition, storage, and access of features for training and serving ML\\n\\nmodels, you have a feature store as a unified repository, which provides functionality for\\n\\nregistering new features to be discovered and used by data scientists. This approach\\n\\nprevents inconsistency between the data used in training the model and the data\\n\\nsubsequently used in serving the model. Data scientists from across the organization are\\n\\nencouraged to use and contribute to the feature store.\\n\\nYour AI efforts are typically driven and maintained by a centralized team that acts as a COE,\\n\\nwith the goal of driving consistency by defining the standards, the procedures, and the templates to create different assets, rather than actively creating them.\\n\\n26\\n\\nScale\\n\\nBridging Data and Technology, “Scale” concerns the extent to which you use'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='26\\n\\nScale\\n\\nBridging Data and Technology, “Scale” concerns the extent to which you use\\n\\ncloud-native ML services that scale with large amounts of data and large\\n\\nnumbers of data processing and ML jobs, with reduced operational overhead.\\n\\nAn organization’s maturity in the Scale theme reflects that organization’s ability to scale data\\n\\nprocessing and ML workloads.\\n\\nTactical maturity\\n\\nTo control the cost of exploring and experimenting with ML and predictive analytics, you’ve\\n\\ngot dedicated hardware or cloud compute instances for a few data scientists. Both the size\\n\\nand the lifespan of these compute instances are dictated by the IT operations team. In\\n\\naddition, your team of data scientists work with small, offline datasets for exploratory data\\n\\nanalysis and processing, using simple data wrangling tools and ready-to-use AI services.\\n\\nData processing and ML training are done locally, using the dedicated data science VMs,'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='analysis and processing, using simple data wrangling tools and ready-to-use AI services.\\n\\nData processing and ML training are done locally, using the dedicated data science VMs,\\n\\nwhich means limited compute power. You are actively exploring the potential of AI by finding\\n\\nsimple, yet interesting, use cases that demonstrate proof of value (POV), so as to increase\\n\\nthe awareness across the organization of the promise of advanced analytics.\\n\\nStrategic maturity\\n\\nYou’ve enabled an enterprise-wide, fully managed cloud data warehouse for ad hoc analytical\\n\\nqueries, for example, using BigQuery. Data is now ingested into your cloud data warehouse from various sources spread across the organization in different systems. Such a scalable\\n\\ndata warehouse enables the data scientists across your organization to perform complex\\n\\nanalytics and information retrieval on a large amount of data in a timely fashion.\\n\\nData ingestion and transformation are performed using a serverless, fault-tolerant,'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='analytics and information retrieval on a large amount of data in a timely fashion.\\n\\nData ingestion and transformation are performed using a serverless, fault-tolerant,\\n\\nautoscaling, parallel processing service for handling large batch and streaming ETL/ELT\\n\\nworkloads to populate the data warehouse and prepare ML datasets. You use tools such as\\n\\nDataflow, Dataproc, and Cloud Data Fusion to combine and process both structured and\\n\\nunstructured data at scale so as to gain actionable insights.\\n\\n27\\n\\nYour data scientists build custom ML models tailored to your data and business needs, using\\n\\nadvanced ML tools and frameworks such as TensorFlow Enterprise. Long-running ML\\n\\ntraining jobs are performed using cloud serverless platforms for distributed training and\\n\\nautomatic hyperparameter tuning — with no dedicated infrastructure — for example, with AI\\n\\nPlatform Training.\\n\\nUsing cloud-native technologies helps your data scientists and engineers focus on data'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='automatic hyperparameter tuning — with no dedicated infrastructure — for example, with AI\\n\\nPlatform Training.\\n\\nUsing cloud-native technologies helps your data scientists and engineers focus on data\\n\\nprocessing and ML modeling activities, enabling them to run numerous jobs at scale on large\\n\\ndatasets with no infrastructure operations overhead.\\n\\nTransformational maturity\\n\\nYou’ve invested in building online complex event processing and stream analytics pipelines,\\n\\npowered by ML, to achieve (near) real-time operation optimization and decision-making. And\\n\\nyou’re engaged in architecting an integrated ML platform, for experimentation and\\n\\nproductionalization, to serve all the data scientists and ML engineers in different teams. This\\n\\napproach provides access to standardized tools, services, compute, processes, and best\\n\\npractices, both from internal and external sources. The goal is to give data science teams a'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='approach provides access to standardized tools, services, compute, processes, and best\\n\\npractices, both from internal and external sources. The goal is to give data science teams a\\n\\nsolid starting point when approaching new ML projects and to provide them with the support\\n\\nto carry them through to completion of those projects.\\n\\nYou use ML accelerators (like GPUs or Cloud TPUs11 using a large amount of data in a short time. In addition, your data engineering team creates\\n\\n1) at scale to train complex ML models,\\n\\nmetadata-driven data processing templates to configure and deploy new workflows without\\n\\ncoding. End-to-end data and ML pipelines are orchestrated and automated with the required\\n\\ninstrumentation.\\n\\n11 A TPU is a Tensor Processing Unit, a chip specifically designed to be faster and more power-efficient than GPUs for certain machine learning tasks.\\n\\n28\\n\\nSecure\\n\\nBridging Data and Process, “Secure” concerns the extent to which you'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='28\\n\\nSecure\\n\\nBridging Data and Process, “Secure” concerns the extent to which you\\n\\nunderstand and protect your data and ML services from unauthorized and\\n\\ninappropriate access, in addition to ensuring responsible and explainable AI.\\n\\nAn organization’s maturity in the Secure theme reflects that organization’s ability to ensure that\\n\\ntheir data is appropriately protected, catalogued, encrypted, and guarded from exfiltration, in\\n\\naccordance with ethical AI principles and practices.\\n\\nTactical maturity\\n\\nYour Cloud Identity and Access Management (IAM) policies predominantly rely on the\\n\\nconvenience of project-level primitive roles (Owner, Editor, Viewer) rather than following the\\n\\nprinciple of least privilege. Default permissions allow for any user to create projects and\\n\\nbilling accounts. Cloud IAM permissions are not continuously monitored, and the admin\\n\\nactivity and data access logs are not systematically audited. Service accounts can be'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='billing accounts. Cloud IAM permissions are not continuously monitored, and the admin\\n\\nactivity and data access logs are not systematically audited. Service accounts can be\\n\\ncreated freely, and private keys for service accounts are not automatically rotated.\\n\\nYou are constantly identifying sensitive data, defined as data containing personally\\n\\nidentifiable information (PII), in order to govern its protection, and the user’s privacy.\\n\\nData classification and protection\\n\\nPoor data protection and sensitive data handling are big blockers for AI adoption, as they can\\n\\nresult in breaches or other issues and, consequently, reputational damage or regulatory\\n\\nsanctions. Data classification and loss prevention, for example, using Cloud Data Loss\\n\\nPrevention, can help you identify and handle sensitive data through encryption, removing,\\n\\nmasking, or coarsening. In addition, establishing a governance policy and adhering to regulatory'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='Prevention, can help you identify and handle sensitive data through encryption, removing,\\n\\nmasking, or coarsening. In addition, establishing a governance policy and adhering to regulatory\\n\\ncompliance are important considerations at this phase. Another key aspect is to track data\\n\\nlineage and its chain of custody, to ensure that the ML models informing business decisions are based on untampered data.\\n\\n29\\n\\nStrategic maturity\\n\\nYour Cloud IAM policies reference a much more granular set of predefined roles, rather than\\n\\nthe coarse primitive roles. In addition, your AI capabilities are supported by clear governance\\n\\nand decision-making responsibilities. Building on this foundation, you’ve also provided a verification route for decisions guided by the principles of AI,12 of trust in AI is maintained throughout the organization. This impacts how confident your\\n\\n1 ensuring that the desired level'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='1 ensuring that the desired level\\n\\norganization is in relying on AI to influence decision-making, while avoiding potential biases in human-centric13\\n\\n2 use cases.\\n\\nExplainable AI\\n\\nExplainable AI methods and techniques render AI solutions and outputs intelligible to human\\n\\nexperts. This approach mitigates the concept of “blackboxing” in ML, where it is hard to explain\\n\\nspecific decisions from an ML model. Your AI-enabled business may impact, or even redefine,\\n\\nmany areas of society. The usefulness and fairness of these AI systems will be gated both by\\n\\ntheir transparency and by your ability to understand, explain, and control them. Activating the\\n\\nright Google tools and capabilities, such as What-If tool, Fairness Indicators, and Explainable AI,\\n\\nwill not only speed up and secure the AI journey, it will also enable your organization to stay\\n\\ncompliant with current regulations, and to react quickly when they change.\\n\\nTransformational maturity'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='will not only speed up and secure the AI journey, it will also enable your organization to stay\\n\\ncompliant with current regulations, and to react quickly when they change.\\n\\nTransformational maturity\\n\\nYou aim to have a comprehensive understanding of the contents of all your data stores, so as\\n\\nto obtain the threat profiles necessary for designing more effective security and data\\n\\ngovernance models, models that consider scenarios of both unauthorized and inappropriate\\n\\naccess. All Cloud Admin activity and data access logs are regularly audited, while automatic\\n\\nalerts have been configured to watch for patterns that match your threat profiles. Cloud IAM\\n\\npermissions and firewall rules are continuously monitored and corrected.'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='alerts have been configured to watch for patterns that match your threat profiles. Cloud IAM\\n\\npermissions and firewall rules are continuously monitored and corrected.\\n\\n12 We recognize that technologies that solve important problems also raise important challenges that we need to address clearly, thoughtfully, and affirmatively. Artificial Intelligence at Google: Our Principles sets out our commitment to develop technology responsibly and establishes specific application areas we will not pursue. 13 People + AI Research (PAIR) is a multidisciplinary research and development team at Google that explores the human side of AI by working with diverse communities. PAIR released a guidebook to help user experience (UX) professionals and product managers follow a human-centered approach to AI.\\n\\n30\\n\\nYour data governance is streamlined, for example, by using automated workflows to rapidly\\n\\nvalidate new use cases against your AI principles — allowing greater focus and discussion'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='30\\n\\nYour data governance is streamlined, for example, by using automated workflows to rapidly\\n\\nvalidate new use cases against your AI principles — allowing greater focus and discussion\\n\\ntime on the edge cases. A team specialized in AI safety and robustness works to improve the\\n\\nreliability and generalizability of ML models, recognizing the importance of well-calibrated uncertainty and protecting against adversarial attacks.14\\n\\n14 Adversarial attacks refers to how ML models can be vulnerable to inputs maliciously constructed by adversaries to force misclassification.\\n\\n31\\n\\nAutomate\\n\\nBridging Technology and Process, “Automate” concerns the extent to which\\n\\nyou are able to deploy, execute, and operate technology for data processing\\n\\nand ML pipelines in production efficiently, frequently, and reliably.\\n\\nAn organization’s maturity in the Automate theme reflects the ability of its AI systems to adapt\\n\\nto changes in data and the environment, which provides the means for making timely data-'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='An organization’s maturity in the Automate theme reflects the ability of its AI systems to adapt\\n\\nto changes in data and the environment, which provides the means for making timely data-\\n\\ndriven decisions.\\n\\nTactical maturity\\n\\nThe technologies adopted across your organization are easy to use, such as data wrangling\\n\\ntools, sheet-based data visualization, and ready-to-use AI services. The process of using\\n\\nsuch technologies to build AI systems is usually manual in every step — from data analysis\\n\\nand preparation, to model training and validation. The process is also driven by experimental\\n\\ncode that is written and executed interactively (for example, using Jupyter Notebooks) by\\n\\ndata scientists until a workable model is produced.\\n\\nData analytics and ML are ad hoc, with no automation, meaning that insights are not\\n\\ndelivered regularly in a timely manner. As is appropriate when directed by this manual, data'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='Data analytics and ML are ad hoc, with no automation, meaning that insights are not\\n\\ndelivered regularly in a timely manner. As is appropriate when directed by this manual, data\\n\\nscientist–driven process, your models are rarely changed or retrained. However, such a\\n\\nmanual process prevents you from working with a large number of models or with frequent\\n\\nupdates to these models.\\n\\nStrategic maturity\\n\\nYou automate data processing and analytics pipelines (for example, using Cloud Composer)\\n\\neither on a recurrent schedule (for example, using Cloud Scheduler) or, to tackle critical\\n\\nevents, on a trigger (like data anomaly detection). You’ve started to standardize processes\\n\\nand to consolidate technology to govern the flow of data from one step of the data lifecycle\\n\\nto the next, that is, from data ingestion and transformation to data analysis and reporting.\\n\\nThis strategy has led to increased agility and decreased cycle times, while reducing data'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='to the next, that is, from data ingestion and transformation to data analysis and reporting.\\n\\nThis strategy has led to increased agility and decreased cycle times, while reducing data\\n\\ndefects, giving developers and business users greater confidence in the insights of analytics for timely decisions.\\n\\n32\\n\\nYou are using ML models in production. However, the models often break when deployed in\\n\\nthe real world because they fail to adapt to changes in the dynamics of the environment or to\\n\\nchanges in the data that describes the environment. For this reason, to regularly update your models with new data, you deploy end-to-end continuous training15\\n\\n1 ML pipelines.\\n\\nIn addition, your trained models are integrated with your automated ETL/ELT routines to\\n\\nperform batch scoring. For online use cases, your models are deployed as services to be\\n\\nused in apps and stream-processing pipelines for serving real-time predictions.\\n\\nContinuous training'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='perform batch scoring. For online use cases, your models are deployed as services to be\\n\\nused in apps and stream-processing pipelines for serving real-time predictions.\\n\\nContinuous training\\n\\nFor reliable continuous training (CT) automation, the validation and quality control aspects of\\n\\nyour ML training need to be backed into your pipelines. That is why you need data validation and\\n\\nmodel validation steps in the beginning and the end of the pipeline, respectively. Such validation\\n\\nsteps act as the “gatekeepers” to your model training. Data validation makes sure that the\\n\\nschema and data types of the new data for retraining the model are as expected. Model\\n\\nvalidation makes sure that the produced model meets the required predictive performance for\\n\\ndeployment, for example, that it outperforms the current model in production and that it meets\\n\\nthe fairness measures — if any have been specified.\\n\\nQuality control in machine learning'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content=\"deployment, for example, that it outperforms the current model in production and that it meets\\n\\nthe fairness measures — if any have been specified.\\n\\nQuality control in machine learning\\n\\nWhen a deployed ML model produces bad predictions, the poor ML quality may imply a wide\\n\\nrange of problems, including the presence of the bugs typical of any program, but also data\\n\\nskews and anomalies, and the absence of proper procedures for evaluating models after\\n\\ntraining and for validating models before deployment. Testing is required not only for\\n\\ndevelopment, but for deployment and production as well. Instrumentations like logging,\\n\\nmonitoring, and notifications are critical to maintain the system's health and operate it reliably.\\n\\nSee Testing and Debugging in Machine Learning and What’s your ML test score? A rubric for ML\\n\\nproduction systems, by Google’s ML experts.\"),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='See Testing and Debugging in Machine Learning and What’s your ML test score? A rubric for ML\\n\\nproduction systems, by Google’s ML experts.\\n\\n15 Continuous training pipelines are automatically executed through schedules or event-based triggers that you can set up with tools like Cloud Scheduler or Cloud Functions. You can orchestrate your training workflows using AI Platform Pipelines.\\n\\n33\\n\\nTransformational maturity\\n\\nYour goal is to develop an ML engineering culture and practice that unifies ML system\\n\\ndevelopment (ML) and ML system operations (Ops). MLOps strongly advocates automation\\n\\nand monitoring at all steps of ML system construction — from integration, testing, and\\n\\nreleasing to deployment, model serving, and infrastructure management. With this approach,\\n\\nyou are working towards shorter development cycles, increased deployment velocity, and\\n\\nmore dependable releases that are also in close alignment with your business objectives.'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='you are working towards shorter development cycles, increased deployment velocity, and\\n\\nmore dependable releases that are also in close alignment with your business objectives.\\n\\nThis is crucial because you have a large number of models in production that require frequent\\n\\nupdating both with new data to capture the emerging patterns and with the new implementation of state-of-the-art ML ideas.\\n\\nAutomatic detection of skews and anomalies in the data through regular data validation jobs\\n\\nhelp data scientists to monitor the performance of their model. In addition, you have an\\n\\nautomated A/B testing system to evaluate the effectiveness of a newly released model\\n\\nservice.\\n\\nContinuous integration and delivery\\n\\nIn ML, continuous integration (CI) covers testing and validating code and components, as well\\n\\nas testing and validating data, data schemas, and models. Continuous delivery (CD) covers two\\n\\naspects: 1) deploying the CT pipeline, which produces a newly trained (and validated) model'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='as testing and validating data, data schemas, and models. Continuous delivery (CD) covers two\\n\\naspects: 1) deploying the CT pipeline, which produces a newly trained (and validated) model\\n\\nevery time it is executed, and 2) deploying the trained model as a prediction service to the\\n\\nserving infrastructure. Services like Cloud Build, Container Registry, Model Registry, and ML\\n\\nMetadata are required to streamline the CI/CD/CT of production ML systems, while maintaining\\n\\nreproducibility, resumability, and reliability.\\n\\n34\\n\\nAdditional technical resources\\n\\nTo get started with ML on Google Cloud, take a look at the following guides, courses, articles, and\\n\\nproduct documentation.\\n\\nRules of Machine Learning offers an overview of best practices for ML engineering.\\n\\nMachine Learning Crash Course provides a fast-paced, practical introduction to ML.\\n\\nData Engineering with Google Cloud Professional Certificate provides the skills you need to advance'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='Machine Learning Crash Course provides a fast-paced, practical introduction to ML.\\n\\nData Engineering with Google Cloud Professional Certificate provides the skills you need to advance\\n\\nyour career in data engineering and recommends training to support your preparation for the\\n\\nindustry-recognized Google Cloud Professional Data Engineer certification.\\n\\nMachine Learning with TensorFlow on Google Cloud teaches you how to use Cloud AI and big data\\n\\nproducts to build production-grade ML systems.\\n\\n\\n\\nTensorFlow in Practice Specialization helps you to discover the tools that software developers use to\\n\\nbuild scalable AI-powered algorithms in TensorFlow, a popular open-source machine learning\\n\\nframework.\\n\\nMLOps: Continuous delivery and automation in ML discusses techniques for implementing and\\n\\nautomating continuous integration (CI), continuous delivery (CD), and continuous training (CT) for ML\\n\\nsystems.\\n\\nGoogle Cloud Smart Analytics describes Google Cloud’s fully managed serverless analytics'),\n",
       " Document(metadata={'source': './PDF.pdf'}, page_content='systems.\\n\\nGoogle Cloud Smart Analytics describes Google Cloud’s fully managed serverless analytics\\n\\nplatform, which can be leveraged to empower the business while eliminating constraints of scale,\\n\\nperformance, and cost.\\n\\nGoogle Cloud AI solutions presents and enables organizations to use high-quality, scalable,\\n\\ncontinuously improving, and fully managed AI solutions.\\n\\n35')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aa838ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "model_name = \"thenlper/gte-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d2fc060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khatt\\AppData\\Local\\Temp\\ipykernel_21808\\3142973650.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c32ab9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_model.embed_query(\"HEY I AM TESTING THIS MODEL for fun\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8205faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "YOUR_PINECONE_KEY=os.getenv('pinecone')\n",
    "pc = Pinecone(api_key=YOUR_PINECONE_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0aa1ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(\"vectorized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "662bf623",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, entry in enumerate(processdata[:10]):\n",
    "    text = entry.page_content\n",
    "    vector = embedding_model.embed_query(text)\n",
    "    data.append(\n",
    "        {\n",
    "            \"id\": \"vec{}\".format(i),\n",
    "            \"values\": vector,\n",
    "            \"metadata\": {\"text\": text}\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a3c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "701aaf60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 10}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.upsert(\n",
    "    vectors=data,\n",
    "    namespace= \"GoogleData\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ea59d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(\"User: \")\n",
    "\n",
    "vectorized_input = embedding_model.embed_query(user_input)\n",
    "context = index.query(\n",
    "    namespace=\"GoogleData\",\n",
    "    vector=vectorized_input,\n",
    "    top_k=1,\n",
    "    include_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1033fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# envpath = \"./database/.env\"\n",
    "# load_dotenv(envpath)\n",
    "load_dotenv()\n",
    "def google(user_input:str)->str:\n",
    "    \"\"\" When user ask about GOOGLE CLOUD AI FRAME WORK \"\"\"\n",
    "\n",
    "    \n",
    "    pc = Pinecone(api_key=PINECONE)\n",
    "    index = pc.Index(\"vectorized\")\n",
    "\n",
    "    model_name = \"thenlper/gte-small\"\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    ")\n",
    "    \n",
    "    vectorized_input = embedding_model.embed_query(user_input)\n",
    "    context = index.query(\n",
    "    namespace=\"GoogleData\",\n",
    "    vector=vectorized_input,\n",
    "    top_k=1,\n",
    "    include_metadata=True\n",
    ")\n",
    "    return context['matches'][0]['metadata']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38866c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khatt\\AppData\\Local\\Temp\\ipykernel_17952\\501838731.py:16: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Machine learning truly is reshaping the marketplace.\\n\\n3 Artificial intelligence is the theory and development of systems able to perform tasks normally requiring human intelligence, such as visual perception, speech recognition, and decision-making. Machine learning is an effective way for building AI systems through automatically discovering useful patterns from data, rather than feeding human-writ- ten rules to the system. 4 Machine Learning: The New Proving Ground for Competitive Advantage. 5 Notes from the AI frontier: Modeling the impact of AI on the world economy, McKinsey & Company, September 2018.\\n\\n4\\n\\nLeveraging the power of AI\\n\\nHow do you structure your teams for success? How can you create, discover, share, and\\n\\nmanage data assets? How can you leverage native cloud technologies to scale AI? How do\\n\\nyou streamline the process of updating and monitoring your ML models in production?\\n\\nWe have a solution for that.\\n\\nThe AI maturity themes'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google(\"What is Ai\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Model-Context-Protocol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
